export class AutomaticAIAnalyzer {
  
  async analyzeImage(imageData: Uint8Array): Promise<{
    isGarbageDetected: boolean
    detectedObjects: Array<{ label: string; score: number }>
    imageHash: string
  }> {
    try {
      console.log('ü§ñ Starting automatic AI analysis...')
      
      // Calculate hash of the image
      const imageHash = await this.calculateImageHash(imageData)
      console.log('üìä Image hash calculated:', imageHash.substring(0, 8) + '...')

      // V√©rifications basiques d'abord
      const imageSize = imageData.length
      if (imageSize < 5000) {
        return {
          isGarbageDetected: false,
          detectedObjects: [{ label: 'Image trop petite', score: 0 }],
          imageHash
        }
      }

      if (imageSize > 10 * 1024 * 1024) {
        return {
          isGarbageDetected: false,
          detectedObjects: [{ label: 'Image trop volumineuse', score: 0 }],
          imageHash
        }
      }

      // Analyser avec plusieurs mod√®les IA pour une meilleure pr√©cision
      const aiResult = await this.performMultiModelAnalysis(imageData)
      
      if (!aiResult.success) {
        // Si l'IA √©choue compl√®tement, on rejette par s√©curit√©
        console.log('‚ùå AI analysis completely failed, rejecting image')
        return {
          isGarbageDetected: false,
          detectedObjects: [{ label: 'Analyse IA impossible - r√©essayez', score: 0 }],
          imageHash
        }
      }

      // Analyser les r√©sultats pour d√©tecter des d√©chets
      const isGarbageDetected = this.detectGarbageFromResults(aiResult.results)
      
      console.log(`ü§ñ AI Decision: ${isGarbageDetected ? 'GARBAGE DETECTED' : 'NO GARBAGE DETECTED'}`)

      return {
        isGarbageDetected,
        detectedObjects: aiResult.results,
        imageHash
      }
    } catch (error) {
      console.error('‚ùå Critical analysis error:', error)
      
      const imageHash = await this.calculateImageHash(imageData)
      // En cas d'erreur critique, rejeter l'image
      return {
        isGarbageDetected: false,
        detectedObjects: [{ label: 'Erreur syst√®me - veuillez r√©essayer', score: 0 }],
        imageHash
      }
    }
  }

  private async performMultiModelAnalysis(imageData: Uint8Array): Promise<{
    success: boolean
    results: Array<{ label: string; score: number }>
  }> {
    const base64Image = this.uint8ArrayToBase64(imageData)
    
    // Mod√®les sp√©cialis√©s pour la d√©tection d'objets
    const models = [
      "microsoft/resnet-50",
      "google/vit-base-patch16-224",
      "facebook/detr-resnet-50"
    ]

    let allResults: Array<{ label: string; score: number }> = []
    let successCount = 0

    for (const model of models) {
      try {
        console.log(`üîç Testing model: ${model}`)
        
        const response = await fetch(
          `https://api-inference.huggingface.co/models/${model}`,
          {
            headers: {
              "Content-Type": "application/json",
            },
            method: "POST",
            body: JSON.stringify({
              inputs: base64Image,
              options: {
                wait_for_model: true,
                use_cache: false
              }
            }),
          }
        )

        if (response.ok) {
          const results = await response.json()
          
          if (Array.isArray(results) && results.length > 0) {
            successCount++
            const modelResults = results.slice(0, 5).map((result: any) => ({
              label: result.label || 'unknown',
              score: Math.round((result.score || 0) * 100)
            }))
            
            allResults.push(...modelResults)
            console.log(`‚úÖ Model ${model} success:`, modelResults)
            
            // Si on a d√©j√† une bonne d√©tection, on peut s'arr√™ter
            if (this.hasHighConfidenceGarbage(modelResults)) {
              console.log(`üéØ High confidence detection found, stopping here`)
              break
            }
          }
        } else {
          console.log(`‚ö†Ô∏è Model ${model} returned status:`, response.status)
        }
      } catch (error) {
        console.error(`‚ùå Error with model ${model}:`, error)
      }
    }

    return {
      success: successCount > 0,
      results: allResults.slice(0, 10) // Garder les 10 meilleurs r√©sultats
    }
  }

  private hasHighConfidenceGarbage(results: Array<{ label: string; score: number }>): boolean {
    const garbageKeywords = [
      'trash', 'garbage', 'waste', 'litter', 'bottle', 'can', 'cup', 'bag',
      'plastic', 'paper', 'wrapper', 'container', 'debris', 'rubbish'
    ]

    return results.some(result => {
      const lowerLabel = result.label.toLowerCase()
      const isGarbageKeyword = garbageKeywords.some(keyword => 
        lowerLabel.includes(keyword)
      )
      return isGarbageKeyword && result.score >= 70 // Seuil √©lev√© pour haute confiance
    })
  }

  private detectGarbageFromResults(results: Array<{ label: string; score: number }>): boolean {
    if (results.length === 0) return false

    // Mots-cl√©s sp√©cifiques aux d√©chets
    const strongGarbageKeywords = [
      'trash', 'garbage', 'waste', 'litter', 'debris', 'rubbish', 'junk'
    ]

    // Objets souvent jet√©s comme d√©chets
    const garbageObjects = [
      'bottle', 'can', 'cup', 'plate', 'bowl', 'fork', 'knife', 'spoon',
      'bag', 'wrapper', 'container', 'box', 'carton', 'plastic', 'paper',
      'cigarette', 'tissue', 'napkin', 'straw', 'lid'
    ]

    // V√©rifier les d√©tections avec scores
    for (const result of results) {
      const lowerLabel = result.label.toLowerCase()
      const score = result.score

      // Mots-cl√©s forts de d√©chets (seuil plus bas)
      const hasStrongKeyword = strongGarbageKeywords.some(keyword => 
        lowerLabel.includes(keyword)
      )
      if (hasStrongKeyword && score >= 30) {
        console.log(`‚úÖ Strong garbage keyword detected: ${result.label} (${score}%)`)
        return true
      }

      // Objets potentiellement jet√©s (seuil plus √©lev√©)
      const hasGarbageObject = garbageObjects.some(object => 
        lowerLabel.includes(object)
      )
      if (hasGarbageObject && score >= 60) {
        console.log(`‚úÖ Garbage object detected: ${result.label} (${score}%)`)
        return true
      }

      // D√©tection de contexte de pollution
      const pollutionContext = ['dirty', 'abandoned', 'scattered', 'littered', 'dumped']
      const hasPollutionContext = pollutionContext.some(context => 
        lowerLabel.includes(context)
      )
      if (hasPollutionContext && score >= 50) {
        console.log(`‚úÖ Pollution context detected: ${result.label} (${score}%)`)
        return true
      }
    }

    console.log('‚ùå No garbage clearly detected in results')
    return false
  }

  private async calculateImageHash(data: Uint8Array): Promise<string> {
    try {
      const hashBuffer = await crypto.subtle.digest('SHA-256', data)
      const hashArray = Array.from(new Uint8Array(hashBuffer))
      return hashArray.map(b => b.toString(16).padStart(2, '0')).join('').substring(0, 32)
    } catch (error) {
      console.error('‚ùå Error calculating hash:', error)
      return `fallback_${Date.now()}_${data.length}`
    }
  }

  private uint8ArrayToBase64(uint8Array: Uint8Array): string {
    let binary = ''
    const len = uint8Array.byteLength
    for (let i = 0; i < len; i++) {
      binary += String.fromCharCode(uint8Array[i])
    }
    return btoa(binary)
  }

  generateValidationMessage(
    isGarbageDetected: boolean, 
    detectedObjects: Array<{ label: string; score: number }>
  ): string {
    if (isGarbageDetected) {
      const detectedItems = detectedObjects
        .filter(obj => obj.score > 30)
        .map(obj => `${obj.label} (${obj.score}%)`)
        .slice(0, 3)
      
      let message = "‚úÖ <b>D√©chets d√©tect√©s automatiquement par l'IA !</b>\n\n"
      
      if (detectedItems.length > 0) {
        message += `üéØ <b>√âl√©ments identifi√©s :</b>\n${detectedItems.join('\n')}\n\n`
      }
      
      message += "ü§ñ Votre signalement a √©t√© <b>valid√© automatiquement</b> par notre syst√®me d'intelligence artificielle. Excellente contribution !"
      
      return message
    } else {
      let message = "‚ùå <b>Aucun d√©chet d√©tect√© par l'IA.</b>\n\n"
      
      if (detectedObjects.length > 0) {
        const obj = detectedObjects[0]
        if (obj.label.includes('petite')) {
          message += "üìè L'image est trop petite. Veuillez prendre une photo plus grande et plus nette."
        } else if (obj.label.includes('volumineuse')) {
          message += "üìÅ L'image est trop volumineuse. Veuillez compresser l'image."
        } else if (obj.label.includes('Erreur') || obj.label.includes('impossible')) {
          message += "‚ö†Ô∏è Probl√®me technique temporaire. Veuillez r√©essayer dans quelques instants."
        } else {
          const detectedItems = detectedObjects
            .filter(obj => obj.score > 20)
            .map(obj => obj.label)
            .slice(0, 3)
          
          if (detectedItems.length > 0) {
            message += `‚ÑπÔ∏è <b>√âl√©ments d√©tect√©s :</b> ${detectedItems.join(', ')}\n\n`
          }
          
          message += "L'IA n'a pas identifi√© de d√©chets clairs. Si vous voyez des d√©chets, veuillez :\n"
          message += "‚Ä¢ Prendre une photo plus proche\n"
          message += "‚Ä¢ Am√©liorer l'√©clairage\n"
          message += "‚Ä¢ Cadrer directement les d√©chets"
        }
      }
      
      return message
    }
  }
}